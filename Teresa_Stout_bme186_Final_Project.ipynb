{
 "metadata": {
  "name": "",
  "signature": "sha256:b7c09240225a879cceb292b8075766a94101004fc09a6753f12999e54a9c478f"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "3 Dimensional Computed Tomography Waist Circumference Calculator <br />\n",
      "\n",
      "Final Project"
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Author: Teresa Stout <br/>\n",
      "Class: BME 186 <br />\n",
      "Instructor: Professor Hans Johnson  <br />\n",
      "Due Date: May 15, 2014"
     ]
    },
    {
     "cell_type": "heading",
     "level": 5,
     "metadata": {},
     "source": [
      "\"Everything Should Be Made as Simple as Possible, But Not Simpler\" - Albert Einstein"
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Abstract"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The goal of this project is to segment and measure the waist circumference (WC) from a subject's 3 dimensional (3D) Computed Tomography (CT) scan. WC is used as a measurement of abdominal obesity. It is associated with a risk factor for mortality in older adults independent of body mass index (BMI) according to [1]. The segmentation and measurements were successfully achieved in a systematic and reproducible approach across the data set. This IPython Notebook uses SimpleITK scripted in Python and is accompanied with the source code, input data, parameters and output data that the author used for validating the algorithm described here. "
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Contents"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "    I. Introduction \n",
      "    II. Method\n",
      "        A. CT Slice Selection\n",
      "        B. Segmentation \n",
      "        C. WC Measurement \n",
      "        D. Unsuccessful Methods\n",
      "            a. Mathematical Morphology \n",
      "            b. Different Edge Detectors\n",
      "    III. Results \n",
      "    IV. Conclusion \n",
      "    V. References "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "_____________________________________________________________________________________________________________________________________"
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "I. Introduction "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "A data set of ten 3 dimensional (3D) Computed Tomography (CT) scans were acquired from Professor Hans Johnson. Professor Johnson converted them to the Neuroimaging Informatics Technology Initiative (NIFTI) file format for processing. They are located in the following repository: https://github.com/tmstout/SimpleITK-Notebooks/CT_Images. \n",
      "\n",
      "The goal of this project is to segment and measure the waist circumference (WC) from these ten 3D CT scans. WC measurements are an important vital measurement in medicine because a large WC has been associated, regardless of body mass index (BMI; calculated as weight in kilograms divided by height in meters squared), with higher circulating levels of inflammatory markers, insulin resistance, type 2 diabetes mellitus, dyslipidemia, and coronary heart disease [1]. Research shows that WC may be associated with these conditions because it is strongly correlated with visceral adipose tissue, which is thought to be more pathogenic than subcutaneous adipose tissue [1]. According to the study by Jacobs et al. that examined the association between WC and risk of mortality in Cancer Prevention Study II (CPS-II) Nutrition Cohort, a large prospective study of predominantly older adults, their results emphasized the importance of WC as a risk for mortality in older adults, neutral of BMI. \n",
      "\n",
      "\n"
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "II. Method"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "For this project, given a 3D CT scan, the WC is retuned by segmenting and measuring the perimeter of the abdominal in one slice of the abdominal cross section of the volumetric CT scan. The slice that is chosen by convention is 5 z-slices above the located umbilicus. \n",
      "\n",
      "First we import the SimpleITK Python module. By convention of the SimpleITK ipython notebooks, our module is imported into the shorter and more pythonic \"sitk\" local name."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import SimpleITK as sitk"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "To visualize the images inline with the ipython notebook we import the following module:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from myshow import myshow, myshow3d"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "A. CT Slice Selection "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Next we import a 3D CT scan to work with from the data set. "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "img1 = sitk.ReadImage(\"/Users/tmstout/Dropbox/CT_Images/CT1.nii.gz\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The data set is of 3D CT scans of the abdominal and chest cavity. We are only interested in the cross section of the abdomen right above the umbilicus since this is where we can measure the perimeter of the abdomen. Axial views of the CT scan are showed below in Figure 1. "
     ]
    },
    {
     "cell_type": "heading",
     "level": 5,
     "metadata": {},
     "source": [
      "Figure 1. Abdominal cross sections of image CT1. "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "myshow3d(img1,zslices = [30, 40, 45, 90])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The umbilicus, also known as the navel, is located in the CT image by the vertical white pixels that connect from the rectus abdominis muscle to the divot on the perimeter of the abdomen. Abdominal slices that contain the umbilicus are shown in Figure 2 below."
     ]
    },
    {
     "cell_type": "heading",
     "level": 5,
     "metadata": {},
     "source": [
      "Figure 2. Slices that contain the umbilicus. "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "myshow3d(img1,zslices = [40, 41, 42])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "By convention for this application, the CT slice chosen to obtain the WC measurement from is 5 slices above the fully connected umbilicus. The second image in Figure 2 shows a fully connected umbilicus. Therefore, we will work on slice 46 shown in Figure 3 below. <br/>\n",
      "\n",
      "By trail and error during the development of this algorithm the author discovered that pixels that appear disconnected in a cross sectional view of the 3D CT image actually may be connected somewhere in the 3D volume. Therefore to make this algorithm work we must extract a single slice to work on independent of the 3d volume, i.e. reduce the dimensionality of the image from a 3D volume to a 2D slice. This is done below and the results are shown in Figure 3. "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "img1_2D = img1[:,:,46]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 5,
     "metadata": {},
     "source": [
      "Figure 3. New 2D image that will be used to obtain the WC measurement. "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "myshow(img1_2D)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "B. Segmentation"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "In order to measure the WC we need to segment the perimeter of the abdomen. We are trying to achieve a single pixel width edge response of the perimeter for the most accurate measurement. The first step in the segmentation is to threshold the image. We use Otsu Thresholding. Otsu thresholding reduces a graylevel image to a binary image by assuming that the image to be thresholded contains a bi-modal histogram (e.g. foreground ad background) then calculates the optimum threshold separating those two classes so that their combined spread (intra-class variance) is minimal [2]. "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "otsuIm = sitk.OtsuThreshold(img1_2D, insideValue = 0, outsideValue = 1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 5,
     "metadata": {},
     "source": [
      "Figure 4. Resulting image after Otsu Thresholding. "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "myshow(otsuIm)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Next we want to segment out the abdomen, which is the largest object shown in Figure 4. We do this by using the connect component image filter and then removing the connect components less than a threshold amount. The connect component image filter labels the objects in a binary image (non-zero pixels are considered to be objects, zero-valued pixels are considered to be background) [3]. Then a label is assigned to each distinct object [3]. "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "connectIm = sitk.ConnectedComponent(otsuIm)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "In order to visualize the distinct labels for each object, we use the LabelToRGB filter to apply a colormap to the label image. This resulting image is shown in Figure 5. The dark red is the object that we wish to isolate. Therefore we use the RelabelComponentImageFilter with a threshold minimum object size of 1000 in order extract from the relabeled output the dark red object. These results are shown in Figure 6 below. "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "rgbIm = sitk.LabelToRGB(connectIm)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 5,
     "metadata": {},
     "source": [
      "Figure 5. Connected component resulting image. "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "myshow(rgbIm)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "filter = sitk.RelabelComponentImageFilter()\n",
      "filter.SetMinimumObjectSize(10000)\n",
      "abdominalIm = filter.Execute(connectIm)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 5,
     "metadata": {},
     "source": [
      "Figure 6. The object of interest segmented out. "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "myshow(abdominalIm)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now that we have the object of interest segmented out, we just need the perimeter of it for the WC measurement. Therefore we need to use an edge detector that returns a single pixel width response for the edge. The perfect edge detector for this cause is the Zero Crossing Edge Detector. It works by finding the closest pixels to the zero-crossing (sign changes) in a signed itk::Image [4]. Pixels closest to zero-crossings are labeled with a foreground value [4]. The algorithm works by detecting differences in sign among neighbors using city-block style connectivity (4-neighbors in 2D) [4]. The result of this filter is shown in Figure 7 below. "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "edgeIm = sitk.ZeroCrossing(sitk.Cast(sitk.RescaleIntensity(abdominalIm), sitk.sitkInt32))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 5,
     "metadata": {},
     "source": [
      "Figure 7. Zero crossing resulting edge image. Edge response is a single pixel width. "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "myshow(edgeIm)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We can repeat some of the above steps to extract only the perimeter of the abdomen object. First we use the Connect Component image filter and set the fullyConneted to True in order to label the objects in the image. Then we again remove the objects less than a thresholded amount using the Relabel Component Image Filter with a Minimum Object Size of 1000. For visualization purposes once again we use the Label to RGB image filter. We see our successful segmentation of the perimeter of the abdomen in Figure 9 below."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "connectIm2 = sitk.ConnectedComponent(sitk.Cast(sitk.RescaleIntensity(edgeIm), sitk.sitkInt32), fullyConnected= True)\n",
      "rgbIm2 = sitk.LabelToRGB(connectIm2)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 5,
     "metadata": {},
     "source": [
      "Figure 8. Colored result of the connect component image filter. "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "myshow(rgbIm2)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "filter = sitk.RelabelComponentImageFilter()\n",
      "filter.SetMinimumObjectSize(1000) \n",
      "perimeterIm = filter.Execute(connectIm2)\n",
      "rgbIm3 = sitk.LabelToRGB(perimeterIm)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 5,
     "metadata": {},
     "source": [
      "Figure 9. Successful segmentation of the abdomen perimeter. "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "myshow(rgbIm3)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "C. WC Measurement "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now that we segmented the perimeter of the abdomen, we need to measure it in order to calculate the waist circumference. By using the Label Statistics Image Filter we can reutrn the counts of each object in an image. Since the background contains the most pixels we will assume this is the largest count for Figure 9. The second largest count then will be the waist circumference of the abdomen. This value is 1161 pixels. Now we need to convert the number of pixels into a measurement by using the size of the pixels. "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "stats = sitk.LabelStatisticsImageFilter()\n",
      "stats.Execute(connectIm2,perimeterIm)\n",
      "print stats"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "For the conversion of pixels to a measurement, we need the spacing of the pixels. The spacing for the 2D image is equal in both x and y direction and is 0.671875. Then we need to multiply the spacing by the number of pixels in the perimeter object. The result is the waist circumference measurement. For CT1.nii the resulting waist circumference is 780.046875. (The author does not know if this is in mm or cm because does not have the original source of the data.)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print perimeterIm.GetSpacing()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "spacing = 0.671875\n",
      "count = 1161\n",
      "WC = spacing*count\n",
      "print \"Wasit Circumference for CT1.nii is:\"\n",
      "print WC"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "D. Unsuccessful Methods "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "During the development of the waist circumference measurement approach, the author ran into dead ends with some types of methods. This section describes the problem methods that will not work for this application and why. "
     ]
    },
    {
     "cell_type": "heading",
     "level": 5,
     "metadata": {},
     "source": [
      "a. Mathematical Morphology "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Mathematical morphology (MM) is a set of methods for the analysis and processing of geometrical structures, based on set theory, lattice theory, topology, and random functions [5]. It is most commonly applied to digital images [5]. The basic morphological operators are erosion, dilation, opening and closing [5]. An attempt was made using MM to segment the perimeter of the abdomen. After thresholding the original 2D slice using Otsu Thresholding, an erosion was done to eliminate all other objects but the abdomen and then a dilate was done to fill the abdomen object as shown in Figure 10 and 11 respectively below."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "erodeIm = sitk.BinaryErode(otsuIm, 4)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 5,
     "metadata": {},
     "source": [
      "Figure 10. Resulting image after erosion. "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "myshow(erodeIm)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "closeIm = sitk.BinaryClosingByReconstruction(erodeIm, 20)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 5,
     "metadata": {},
     "source": [
      "Figure 11. Resulting closing by reconstruction image. "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "myshow(closeIm)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The isolation of the abdomen object seemed successful in Figure 11. The author could follow the same process to find the perimeter using an edge detector and counting the number of connected components on the perimeter. However, the MM operators did not preserve the original shape of the abdomen due to the nature of their method. Figure 12 shows the difference image of Figure 11 and the original Otsu thresholded image of Figure 4. One can observe in Figure 12 thick abdomen perimeter lines which were removed during the erosion phase. Therefore the resulting WC measurement will be incorrect."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "subtractIm = sitk.Subtract(closeIm, otsuIm)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 5,
     "metadata": {},
     "source": [
      "Figure 12. Difference image showing the faliure of the MM approach. "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "myshow(subtractIm)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 5,
     "metadata": {},
     "source": [
      "b. Different Edge Detectors "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "After the isolation of the abdomen object was obtained, the author tried several different edge detectors. The goal was to find an edge detector that gave a single pixel width response in order to get the most accurate WC measurement. The zero-crossing edge detector preformed the best. Edge detectors that failed included: Gradient Magnitude, Canny Edge Detection, and Sobel Edge Detection, shown in Figures 13-15 respectively. One can see that these edge detectors did not return a single pixel width response for the perimeter of the abdomen. "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "gradientMagIm = sitk.GradientMagnitude(abdominalIm)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 5,
     "metadata": {},
     "source": [
      "Figure 13. Gradient magnitude image."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "myshow(gradientMagIm)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cannyIm = sitk.CannyEdgeDetection(sitk.Cast(sitk.RescaleIntensity(abdominalIm), sitk.sitkFloat32))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 5,
     "metadata": {},
     "source": [
      "Figure 14. Canny edge detection image. "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "myshow(cannyIm)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sobelIm = sitk.SobelEdgeDetection(sitk.Cast(sitk.RescaleIntensity(abdominalIm), sitk.sitkFloat32))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 5,
     "metadata": {},
     "source": [
      "Figure 15. Sobel edge detection image. "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "myshow(sobelIm)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "III. Results"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "This section summerizes the WC measurement results found for each image in the data set. The calculations were done in a seperate notebook in the same repository titled: Teresa_Stout_bme186_Final_Project_Result_Section_Calculations.ipynb. "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "                           Image Title Waist  |  Circumference Measurement \n",
      "                           ______________________________________________\n",
      "                           \n",
      "                               CT1.nii.gz              780.046875\n",
      "                               CT2.nii.gz              759.21875\n",
      "                               CT3.nii.gz              774.945178509\n",
      "                               CT4.nii.gz              781.839708567\n",
      "                               CT5.nii.gz              756.956890821\n",
      "                               CT6.nii.gz              768.523294926\n",
      "                               CT7.nii.gz              723.609375\n",
      "                               CT8.nii.gz              726.296875\n",
      "                               CT9.nii.gz              780.966658711\n",
      "                               CT10.nii.gz             763.447130561\n",
      "                               \n",
      "                    "
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "IV. Conclusion "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "WC is used as a measurement of abdominal obesity. The author developed a successful method for segmenting and measuring the waist circumference for the data set of 3D volume abdominal and chest CT scans.  "
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "V. References"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "[1] Jacobs, E. J., C. C. Newton, Y. Wang, A. V. Patel, M. L. Mccullough, P. T. Campbell, M. J. Thun, and S. M. Gapstur. \"Waist Circumference and All-Cause Mortality in a Large US Cohort.\" Archives of Internal Medicine 170.15 (2010): 1293-301. Print. <br/>\n",
      "[2]  \"Otsu's Method.\" Wikipedia. Wikimedia Foundation, 25 Apr. 2014. Web. 14 May 2014.<br/>\n",
      "[3] \"ITK: Itk::ConnectedComponentImageFilter Class Template Reference.\" ITK: Itk::ConnectedComponentImageFilter Class Template Reference. Insight Segmentation and Registration Toolkit, n.d. Web. 14 May 2014. <br/>\n",
      "[4] \"ITK: Itk::ZeroCrossingImageFilter Class Template Reference.\" ITK: Itk::ZeroCrossingImageFilter Class Template Reference. Insight Segmentation and Registration Toolkit, n.d. Web. 14 May 2014. <br/>\n",
      "[5] \"Mathematical Morphology.\" Wikipedia. Wikimedia Foundation, 28 Apr. 2014. Web. 14 May 2014.<br/>\n"
     ]
    }
   ],
   "metadata": {}
  }
 ]
}